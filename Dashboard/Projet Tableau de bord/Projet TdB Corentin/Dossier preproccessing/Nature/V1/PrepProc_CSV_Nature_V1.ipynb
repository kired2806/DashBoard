{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy as sp\n",
    "nlp = sp.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDate(df: pd.DataFrame, date_column: str):\n",
    "    \"\"\"\n",
    "    Foramts dates in MM YYYY format\n",
    "    \n",
    "    In :\n",
    "        df : dataFrame from Nature CSV articles\n",
    "        date_column : name of the column containing the dates\n",
    "    \n",
    "    Out :\n",
    "        N.A. (modification of the dataframe provided as input)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Correction of dates\n",
    "    corrDate = [('January', '01'),\n",
    "                ('February', '02'),\n",
    "                ('March', '03'),\n",
    "                ('April', '04'),\n",
    "                ('May', '05'),\n",
    "                ('June', '06'),\n",
    "                ('July', '07'),\n",
    "                ('August', '08'),\n",
    "                ('September', '09'),\n",
    "                ('October', '10'),\n",
    "                ('November', '11'),\n",
    "                ('December', '12')]\n",
    "\n",
    "    cleanDate = []\n",
    "    date = np.array(df[date_column])\n",
    "    \n",
    "    for i in date:\n",
    "        try:\n",
    "            if type(int(i[0:2])) is int:\n",
    "                dateTemp = i[3:]\n",
    "\n",
    "        except:\n",
    "            dateTemp = i\n",
    "\n",
    "        for k, v in corrDate:\n",
    "            if dateTemp.replace(k, v) != dateTemp:\n",
    "                cleanDate.append(dateTemp.replace(k, v))\n",
    "\n",
    "                \n",
    "    if len(cleanDate) != 0:\n",
    "        df[date_column] = cleanDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(col_text: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Cleaning of the text from the dataframe provided\n",
    "\n",
    "    In :\n",
    "        col_text: the column containing the text\n",
    "\n",
    "    Out :\n",
    "        Give a column ( <=> list) containing the cleaned texts\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    col_clean_text = []\n",
    "    for i in tqdm(col_text):\n",
    "        text = nlp(i)\n",
    "        text_clean = []\n",
    "\n",
    "        for token in text:\n",
    "            if token.is_stop == False and token.pos_ not in ['PUNCT', 'SPACE'] and token.is_alpha == True:\n",
    "                text_clean.append(token.lemma_)\n",
    "\n",
    "        col_clean_text.append(\" \".join(text_clean))\n",
    "        \n",
    "    return col_clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_freq_words(tfidf_vect, mat_tfidf, n_terms: int) -> list: \n",
    "    \"\"\"\n",
    "    This function allows you to find the n_terms most important words ( <=> most frequent) of each article.\n",
    "\n",
    "    In :\n",
    "        mat_tfidf: tf_idf of articles\n",
    "        n_terms: the number of desired terms\n",
    "        \n",
    "    Out :\n",
    "        column with the most frequent words\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    freq_word = []\n",
    "    labels = tfidf_vect.get_feature_names()\n",
    "    \n",
    "    for l in tqdm(range(mat_tfidf.shape[0])):\n",
    "        ligne = pd.DataFrame(mat_tfidf[l].todense())\n",
    "        \n",
    "        for i,r in ligne.iterrows():\n",
    "            freq_word.append([','.join([labels[t] for t in np.argsort(r)[-n_terms:]])])\n",
    "            \n",
    "    return freq_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Loading\n",
    "df_all = pd.read_csv(\"../../../Data/Nature/Not_Clean/articles_nature_V1.csv\", sep=\";\")\n",
    "df_all = df_all.drop(df_all.columns[[0]], axis='columns')\n",
    "print(\"Load OK \\n\")\n",
    "\n",
    "#Suppression des abstract à chaque début d'article\n",
    "df_all['text'] =[i[8:] for i in df_all['text']]\n",
    "print(\"Delete Abstract OK \\n\")\n",
    "\n",
    "#lower sur la colonnr text\n",
    "df_all['text'] = df_all['text'].str.lower()\n",
    "print(\"lower texts OK \\n\")\n",
    "\n",
    "# Prepro des dates\n",
    "cleanDate(df_all, 'date')\n",
    "print(\"Dates OK \\n\")\n",
    "\n",
    "# Nettoyage du texte (30 min)\n",
    "df_all['text'] = clean_text(df_all['text'])\n",
    "print(\"Cleaning texts OK \\n\")\n",
    "\n",
    "#TF-IDF\n",
    "tfidf_vect = TfidfVectorizer(lowercase=False, stop_words=None)\n",
    "X = tfidf_vect.fit_transform(df_all['text'])\n",
    "print(\"TF-IDF OK \\n\")\n",
    "\n",
    "#Mot clé par article (2 min)\n",
    "df_all['key_words'] = get_most_freq_words(tfidf_vect, X, 5)\n",
    "print(\"Keywords OK \\n\")\n",
    "\n",
    "#Export du CSV pr import dataBase\n",
    "df_all.to_csv('../../../Data/Nature/Clean/articles_nature_clean_V1.csv', sep = \";\", index = True)\n",
    "print(\"Export OK \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1167px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
